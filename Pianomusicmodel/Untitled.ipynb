{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterException",
     "evalue": "File not found or no such format found for: U",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f64b7e93fb9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Extract notes and chords from MIDI files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmidi_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mnotes_to_parse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(value, forceSource, number, format, **keywords)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;31m# all else, including MidiBytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparseData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseData\u001b[0;34m(dataStr, number, format, **keywords)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     '''\n\u001b[1;32m   1166\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataStr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseData\u001b[0;34m(self, dataStr, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0museFormat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'romanText'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m                 raise ConverterException('File not found or no such format found for: %s' %\n\u001b[0m\u001b[1;32m    692\u001b[0m                                          dataStrMakeStr)\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterException\u001b[0m: File not found or no such format found for: U"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from music21 import *\n",
    "import os\n",
    "    \n",
    "\n",
    "# Step 1: Data Collection\n",
    "# Load the MIDI files\n",
    "\n",
    "directory = 'Users//nickdory//Documents//Pianomusicmodel//BachInventions//'\n",
    " \n",
    "    \n",
    "    \n",
    "# # iterate over files in\n",
    "# # that directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     f = os.path.join(directory, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(f):\n",
    "#         print(f)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "midi_files = (\"Users/nickdory/Documents/Pianomusicmodel/BachInventions/\")\n",
    "\n",
    "    # Step 2: Data Preprocessing\n",
    "notes = []\n",
    "\n",
    "    # Extract notes and chords from MIDI files\n",
    "for file in midi_files:\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "\n",
    "    try:\n",
    "            # Piano instrument parts\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse()\n",
    "    except:\n",
    "            # If no piano parts found, take all notes\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "        # Store pitch and duration of each note/chord\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    # Step 3: Feature Extraction\n",
    "    # Define vocabulary of unique notes and chords\n",
    "pitch_names = sorted(set(notes))\n",
    "n_vocab = len(pitch_names)\n",
    "\n",
    "    # Map notes/chords to numerical representation\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitch_names))\n",
    "\n",
    "    # Create input sequences and corresponding output labels\n",
    "sequence_length = 100  # Number of previous notes to consider\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(len(notes) - sequence_length):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    # Reshape and normalize input data\n",
    "n_patterns = len(network_input)\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "    # Convert output labels to categorical format\n",
    "network_output = tf.keras.utils.to_categorical(network_output)\n",
    "\n",
    "    # Step 4: Model Architecture\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=(network_input.shape[1], network_input.shape[2])))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(n_vocab, activation='softmax'))\n",
    "\n",
    "    # Step 5: Model Training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(network_input, network_output, epochs=50, batch_size=64)\n",
    "\n",
    "    # Step 6: Model Evaluation\n",
    "\n",
    "    # Step 7: Music Generation\n",
    "    # Generate new music\n",
    "start_sequence = network_input[0]  # Initial input sequence\n",
    "generated_notes = []\n",
    "\n",
    "for _ in range(500):\n",
    "    input_sequence = np.reshape(start_sequence, (1, len(start_sequence), 1))\n",
    "    input_sequence = input_sequence / float(n_vocab)\n",
    "\n",
    "        # Predict the next note\n",
    "    predicted_probs = model.predict(input_sequence)[0]\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    predicted_note = pitch_names[predicted_index]\n",
    "    generated_notes.append(predicted_note)\n",
    "\n",
    "    # Slide the input sequence window by one note\n",
    "start_sequence.append(predicted_index)\n",
    "start_sequence = start_sequence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
